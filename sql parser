import re
import pandas as pd
from collections import defaultdict

# Dictionary to map column names to tables and databases
column_lookup = {
    "Database Name": ["profile", "profile", "profile", "profile"],
    "Table Name": ["users", "users", "addresses", "addresses"],
    "Column Name": ["id", "name", "address", "id"]
}

# Create DataFrame from the dictionary
df_columns = pd.DataFrame(column_lookup)

# Ensure case insensitivity by making the column names lowercase
df_columns["Column Name"] = df_columns["Column Name"].str.lower()

def extract_tables_and_columns(sql_query, df_columns):
    table_aliases = {}
    table_columns = defaultdict(lambda: defaultdict(set))

    # Normalize query to handle case variations
    sql_query = sql_query.strip().lower()  # Convert SQL to lowercase

    # Regex to find table aliases in FROM and JOIN clauses
    table_pattern = re.findall(r'\bfrom\s+((?:\w+\.){0,2}\w+)\s*(\w+)?', sql_query, re.IGNORECASE)
    table_pattern += re.findall(r'\bjoin\s+((?:\w+\.){0,2}\w+)\s*(\w+)?', sql_query, re.IGNORECASE)

    for table, alias in table_pattern:
        if alias:
            table_aliases[alias] = table  # Map alias to actual table
        table_aliases[table] = table  # Store actual table as well

    # Reverse alias lookup for JOIN conditions
    alias_to_table = {alias: table for alias, table in table_aliases.items() if alias}

    # Regex to find selected columns with table aliases
    column_pattern = re.search(r'\bselect\s+([\w\s,.*]+?)\s+\bfrom\b', sql_query, re.IGNORECASE)

    columns = []
    if column_pattern:
        columns = column_pattern.group(1).split(',')
        for col in columns:
            col = col.strip()
            if '.' in col:
                alias, column = col.rsplit('.', 1)
                table = table_aliases.get(alias, alias)  # Resolve alias to actual table
                db_table = table.rsplit('.', 1) if '.' in table else (None, table)
                table_columns[db_table[0]][db_table[1]].add(column)
            else:
                # Handle columns without table aliases (search the provided dictionary for the table)
                matched_row = df_columns[df_columns["Column Name"] == col]
                if not matched_row.empty:
                    db = matched_row.iloc[0]["Database Name"]
                    table = matched_row.iloc[0]["Table Name"]
                    table_columns[db][table].add(col)

    # Extract columns from ON conditions in JOINs
    join_conditions = re.findall(r'on\s+(\w+)\.(\w+)\s*=\s*(\w+)\.(\w+)', sql_query, re.IGNORECASE)
    for alias1, col1, alias2, col2 in join_conditions:
        table1 = table_aliases.get(alias1, alias1)  # Resolve alias to actual table
        table2 = table_aliases.get(alias2, alias2)
        db_table1 = table1.rsplit('.', 1) if '.' in table1 else (None, table1)
        db_table2 = table2.rsplit('.', 1) if '.' in table2 else (None, table2)
        table_columns[db_table1[0]][db_table1[1]].add(col1)
        table_columns[db_table2[0]][db_table2[1]].add(col2)

    # Prepare the data for the final DataFrame
    data = []
    for db, tables in table_columns.items():
        for table, columns in tables.items():
            for column in columns:
                data.append({
                    "Database Name": db,
                    "Table Name": table,
                    "Column Name": column
                })

    return pd.DataFrame(data)

# Example usage
sql_query = """
SELECT a.id, name, address FROM profile.users a 
LEFT JOIN profile.address b ON a.id = b.id
"""
df = extract_tables_and_columns(sql_query, df_columns)
print(df)
